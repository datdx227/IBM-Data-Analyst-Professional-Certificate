{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45 to 60** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will be performing data wrangling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Identify duplicate values in the dataset.\n",
    "\n",
    "-   Remove duplicate values from the dataset.\n",
    "\n",
    "-   Identify missing values in the dataset.\n",
    "\n",
    "-   Impute the missing values in the dataset.\n",
    "\n",
    "-   Normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will identify duplicate values in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Find how many duplicate rows exist in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 154 duplicate rows.\n",
      "There are 154 duplicate Respondants.\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print('There are', df.duplicated().sum(), 'duplicate rows.')\n",
    "print('There are', df.duplicated('Respondent').sum(), 'duplicate Respondants.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicate rows from the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11398, 85)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if duplicates were actually dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate rows.\n",
      "There are 0 duplicate Respondants.\n"
     ]
    }
   ],
   "source": [
    "print('There are', df.duplicated().sum(), 'duplicate rows.')\n",
    "print('There are', df.duplicated('Respondent').sum(), 'duplicate Respondants.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the missing values for all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respondent                   0\n",
      "MainBranch                   0\n",
      "Hobbyist                     0\n",
      "OpenSourcer                  0\n",
      "OpenSource                  81\n",
      "Employment                   0\n",
      "Country                      0\n",
      "Student                     51\n",
      "EdLevel                    112\n",
      "UndergradMajor             737\n",
      "EduOther                   164\n",
      "OrgSize                     96\n",
      "DevType                     65\n",
      "YearsCode                    9\n",
      "Age1stCode                  13\n",
      "YearsCodePro                16\n",
      "CareerSat                    0\n",
      "JobSat                       1\n",
      "MgrIdiot                   493\n",
      "MgrMoney                   497\n",
      "MgrWant                    493\n",
      "JobSeek                      0\n",
      "LastHireDate                 0\n",
      "LastInt                    413\n",
      "FizzBuzz                    37\n",
      "JobFactors                   3\n",
      "ResumeUpdate                39\n",
      "CurrencySymbol               0\n",
      "CurrencyDesc                 0\n",
      "CompTotal                  809\n",
      "CompFreq                   206\n",
      "ConvertedComp              816\n",
      "WorkWeekHrs                122\n",
      "WorkPlan                   121\n",
      "WorkChallenge              164\n",
      "WorkRemote                   8\n",
      "WorkLoc                     32\n",
      "ImpSyn                       5\n",
      "CodeRev                      1\n",
      "CodeRevHrs                2426\n",
      "UnitTests                   29\n",
      "PurchaseHow                196\n",
      "PurchaseWhat                38\n",
      "LanguageWorkedWith          11\n",
      "LanguageDesireNextYear     134\n",
      "DatabaseWorkedWith         453\n",
      "DatabaseDesireNextYear    1042\n",
      "PlatformWorkedWith         411\n",
      "PlatformDesireNextYear     544\n",
      "WebFrameWorkedWith        1393\n",
      "WebFrameDesireNextYear    1617\n",
      "MiscTechWorkedWith        2182\n",
      "MiscTechDesireNextYear    1455\n",
      "DevEnviron                  29\n",
      "OpSys                       34\n",
      "Containers                  82\n",
      "BlockchainOrg             2322\n",
      "BlockchainIs              2610\n",
      "BetterLife                  98\n",
      "ITperson                    35\n",
      "OffOn                       38\n",
      "SocialMedia                293\n",
      "Extraversion                20\n",
      "ScreenName                 507\n",
      "SOVisit1st                 325\n",
      "SOVisitFreq                  5\n",
      "SOVisitTo                    1\n",
      "SOFindAnswer                 3\n",
      "SOTimeSaved                 50\n",
      "SOHowMuchTime             1917\n",
      "SOAccount                    1\n",
      "SOPartFreq                1128\n",
      "SOJobs                       6\n",
      "EntTeams                     5\n",
      "SOComm                       0\n",
      "WelcomeChange               85\n",
      "SONewContent              1965\n",
      "Age                        287\n",
      "Gender                      73\n",
      "Trans                      123\n",
      "Sexuality                  542\n",
      "Ethnicity                  675\n",
      "Dependents                 140\n",
      "SurveyLength                19\n",
      "SurveyEase                  14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many rows are missing in the column 'WorkLoc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 missing values in the column 'WorkLoc'\n",
      "There are 112 missing values in the column 'EdLevel'\n",
      "There are 0 missing values in the column 'Country'\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(\"There are\", df['WorkLoc'].isnull().sum(), \"missing values in the column 'WorkLoc'\")\n",
    "print(\"There are\", df['EdLevel'].isnull().sum(), \"missing values in the column 'EdLevel'\")\n",
    "print(\"There are\", df['Country'].isnull().sum(), \"missing values in the column 'Country'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the  value counts for the column WorkLoc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 unique Work Locations in the survey:\n",
      "\n",
      "WorkLoc                                    value count\n",
      "-------                                    -----------\n",
      "Office                                            6806\n",
      "Home                                              3589\n",
      "Other place, such as a coworking space or cafe     971\n",
      "Name: WorkLoc, dtype: int64\n",
      "\n",
      "\n",
      "There are 2 unique Employment values in the survey:\n",
      "\n",
      "Employment        value count\n",
      "----------        -----------\n",
      "Employed full-time    10968\n",
      "Employed part-time      430\n",
      "Name: Employment, dtype: int64\n",
      "\n",
      "\n",
      "There are 12 unique UndergradMajor values in the survey:\n",
      "\n",
      "UndergradMajor        value count\n",
      "---------------        -----------\n",
      "Computer science, computer engineering, or software engineering          6953\n",
      "Information systems, information technology, or system administration     794\n",
      "Another engineering discipline (ex. civil, electrical, mechanical)        759\n",
      "Web development or web design                                             410\n",
      "A natural science (ex. biology, chemistry, physics)                       403\n",
      "Mathematics or statistics                                                 372\n",
      "A business discipline (ex. accounting, finance, marketing)                244\n",
      "A social science (ex. anthropology, psychology, political science)        210\n",
      "A humanities discipline (ex. literature, history, philosophy)             207\n",
      "Fine arts or performing arts (ex. graphic design, music, studio art)      161\n",
      "I never declared a major                                                  124\n",
      "A health science (ex. nursing, pharmacy, radiology)                        24\n",
      "Name: UndergradMajor, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('There are', df['WorkLoc'].nunique(), 'unique Work Locations in the survey:')\n",
    "\n",
    "print('\\nWorkLoc                                    value count')      \n",
    "print('-------                                    -----------')\n",
    "print(df['WorkLoc'].value_counts())\n",
    "\n",
    "print('\\n\\nThere are', df['Employment'].nunique(), 'unique Employment values in the survey:')\n",
    "\n",
    "print('\\nEmployment        value count')      \n",
    "print('----------        -----------')\n",
    "print(df['Employment'].value_counts())\n",
    "\n",
    "print('\\n\\nThere are', df['UndergradMajor'].nunique(), 'unique UndergradMajor values in the survey:')\n",
    "\n",
    "print('\\nUndergradMajor        value count')      \n",
    "print('---------------        -----------')\n",
    "print(df['UndergradMajor'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the value that is most frequent (majority) in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131596.7316197316\n",
      "57745.0\n"
     ]
    }
   ],
   "source": [
    "#make a note of the majority value here, for future reference\n",
    "print(df['ConvertedComp'].mean())\n",
    "print(df['ConvertedComp'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for missing data in WorkLoc:\n",
      "\n",
      "False    11366\n",
      "True        32\n",
      "Name: WorkLoc, dtype: int64\n",
      "\n",
      "Here are the first 10 rows missing values for WorkLoc:\n",
      "      Respondent WorkLoc\n",
      "130          285     NaN\n",
      "242          550     NaN\n",
      "866         1847     NaN\n",
      "1455        2826     NaN\n",
      "1753        3536     NaN\n",
      "2339        4768     NaN\n",
      "2689        5562     NaN\n",
      "2788        5769     NaN\n",
      "3165        6613     NaN\n",
      "3213        6721     NaN\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "import numpy as np\n",
    "\n",
    "workloc_highest = 'Office'\n",
    "\n",
    "missing_data = df.isnull()\n",
    "#print(missing_data.head(5))\n",
    "\n",
    "print('\\nValue counts for missing data in WorkLoc:\\n')\n",
    "print( missing_data['WorkLoc'].value_counts())\n",
    "\n",
    "\n",
    "print('\\nHere are the first 10 rows missing values for WorkLoc:')\n",
    "print(df[missing_data['WorkLoc']][['Respondent','WorkLoc']].head(10))\n",
    "\n",
    "df['WorkLoc'].replace(np.nan, workloc_highest, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After imputation there should ideally not be any empty rows in the WorkLoc column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if imputing was successful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New value counts for missing data in WorkLoc:\n",
      "\n",
      "False    11366\n",
      "True        32\n",
      "Name: WorkLoc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print('\\nNew value counts for missing data in WorkLoc:\\n')\n",
    "print(missing_data['WorkLoc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns in the dataset that talk about compensation.\n",
    "\n",
    "One is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n",
    "\n",
    "The other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\". \n",
    "\n",
    "This makes it difficult to compare the total compensation of the developers.\n",
    "\n",
    "In this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n",
    "\n",
    "Once this column is ready, it makes comparison of salaries easy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List out the various categories in the column 'CompFreq'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly     6073\n",
      "Monthly    4788\n",
      "Weekly      331\n",
      "Name: CompFreq, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "print(df['CompFreq'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double click to see the **Hint**.\n",
    "\n",
    "<!--\n",
    "\n",
    "Use the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n",
    "\n",
    "If the CompFreq is Yearly then use the exising value in CompTotal\n",
    "If the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\n",
    "If the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "df.loc[df['CompFreq'] == 'Yearly', 'NormalizedAnnualCompensation']  = 1  * df['CompTotal']\n",
    "df.loc[df['CompFreq'] == 'Monthly', 'NormalizedAnnualCompensation'] = 12 * df['CompTotal']\n",
    "df.loc[df['CompFreq'] == 'Weekly', 'NormalizedAnnualCompensation']  = 52 * df['CompTotal']\n",
    "\n",
    "\n",
    "df[['CompTotal','CompFreq','NormalizedAnnualCompensation']].head(20)\n",
    "\n",
    "df['NormalizedAnnualCompensation'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright Â© 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
